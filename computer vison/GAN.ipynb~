{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44aa54c017c3b8ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:17:09.812022Z",
     "start_time": "2024-10-16T03:17:04.253149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 22:53:14.096966: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-17 22:53:14.121351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-17 22:53:14.145687: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-17 22:53:14.152624: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-17 22:53:14.172285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-17 22:53:15.239514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "# import env  # 导入 env.py 文件中的所有内容\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# 测试 TensorFlow 是否能使用 GPU（如果安装了 GPU 版本）\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7bde1c7d6322b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T04:18:54.068771Z",
     "start_time": "2024-10-16T04:18:54.047774Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils.data as dl\n",
    "# 定义数据增强和预处理\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))  # 加入随机擦除\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义图像预处理（类似于 ImageDataGenerator 中的 rescale）\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 转换为 Tensor\n",
    "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # 正则化\n",
    "])\n",
    "\n",
    "\n",
    "# 读取训练和验证数据\n",
    "train_df = pd.read_csv('train.csv')  # 假设train_data.csv保存图像文件名和标签\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# 定义自定义训练数据集类\n",
    "class CustomImageDatasetTrain(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, str(self.dataframe.iloc[idx, 0]) + '.jpg')\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        # 获取第6列作为标签\n",
    "        label = self.dataframe.iloc[idx, 6]\n",
    "\n",
    "        # 转换标签为 torch.Tensor\n",
    "        label = torch.tensor(label, dtype=torch.float32)  # 根据任务需要设置 dtype，如 long 或 float32\n",
    "\n",
    "        # 应用 transform，如果有的话\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 定义自定义测试数据集类\n",
    "class CustomImageDatasetTest(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, str(self.dataframe.iloc[idx, 0]) + '.jpg')\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        # 获取第0列作为标签（测试集可能需要不同的标签处理逻辑）\n",
    "        label = self.dataframe.iloc[idx, 0]\n",
    "\n",
    "        # 转换标签为 torch.Tensor\n",
    "        label = torch.tensor(label, dtype=torch.float32)  # 根据任务需要设置 dtype\n",
    "\n",
    "        # 应用 transform，如果有的话\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "# 1. 计算训练集和验证集的大小（按 2:8 切分）\n",
    "train_size = int(0.8 * len(train_df))\n",
    "val_size = len(train_df) - train_size\n",
    "# 2. 使用 Pandas 的 sample() 方法随机采样训练集，剩下的作为验证集\n",
    "train_df_split = train_df.sample(n=train_size, random_state=42)\n",
    "val_df_split = train_df.drop(train_df_split.index)\n",
    "\n",
    "train_dataset = CustomImageDatasetTrain(dataframe=train_df_split, img_dir='train', transform=train_transform)\n",
    "val_dataset = CustomImageDatasetTrain(dataframe=val_df_split, img_dir='train', transform=test_transform)\n",
    "test_dataset = CustomImageDatasetTest(dataframe=test_df, img_dir='test', transform=val_transform)\n",
    "\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa8ed70-92b7-4635-8c76-46fbb99f271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train_loader: 6144\n",
      "Batch size: 32\n",
      "Total batches: 192\n"
     ]
    }
   ],
   "source": [
    "def print_train_loader_info(train_loader):\n",
    "    # 打印训练数据的总数量\n",
    "    total_samples = len(train_loader.dataset)\n",
    "    # 打印每个 batch 的大小\n",
    "    batch_size = train_loader.batch_size\n",
    "    # 打印总 batch 数量\n",
    "    total_batches = len(train_loader)\n",
    "\n",
    "    print(f\"Total samples in train_loader: {total_samples}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Total batches: {total_batches}\")\n",
    "print_train_loader_info(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb09d85fa035bff0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T04:19:20.094855Z",
     "start_time": "2024-10-16T04:19:17.879469Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# from utils.visualization import *\n",
    "# # 打印每个数据加载器的前五条数据\n",
    "# print_batch_info(train_loader, \"Train Loader\")\n",
    "# print_batch_info(val_loader, \"Validation Loader\")\n",
    "# print_batch_info(test_loader, \"Test Loader\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0160abdc-6ca7-4ad4-8ad6-c135556a5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b859c396f021321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T04:20:21.684985Z",
     "start_time": "2024-10-16T04:20:14.930056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/3] [D loss: 0.2894] [G loss: 0.8963]\n",
      "[Epoch 1/3] [D loss: 0.2396] [G loss: 1.0421]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# ResNet配置\n",
    "class ResNetConfig:\n",
    "    def __init__(self, model_name='resnet50'):\n",
    "        self.model_name = model_name\n",
    "        self.pretrained = True\n",
    "        self.freeze_encoder = False\n",
    "        self.hidden_dim = 1024\n",
    "        self.dropout = 0.5\n",
    "        self.output_dim = 1  # 回归输出一个值\n",
    "        self.lr = 1e-4\n",
    "        self.epochs = 15\n",
    "        self.batch_size = 32\n",
    "        self.step_size = 10\n",
    "        self.gamma = 0.1\n",
    "        self.loss_fn = nn.SmoothL1Loss()\n",
    "        self.image_size = (224, 224)\n",
    "        self.device = torch.device( \"cpu\")\n",
    "        self.noise_dim = 100  # GAN 噪声向量的维度\n",
    "        self.img_channels = 3\n",
    "        self.img_size = 224  # 图像大小\n",
    "\n",
    "# ResNet 模型定义\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        if config.model_name == 'resnet50':\n",
    "            self.base_model = models.resnet50(pretrained=config.pretrained)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {config.model_name}\")\n",
    "\n",
    "        if config.freeze_encoder:\n",
    "            for param in self.base_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        num_ftrs = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.hidden_dim, config.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# 自定义数据集类\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test  # 标志，标识是否为测试集\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取图像文件路径\n",
    "        img_name = os.path.join(self.img_dir, str(self.dataframe.iloc[idx, 0]) + '.jpg')\n",
    "        \n",
    "        # 尝试打开图像，如果图像文件不存在则处理异常\n",
    "        try:\n",
    "            image = Image.open(img_name).convert('RGB')  # 确保转换为RGB格式\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image {img_name} not found.\")\n",
    "            return None  # 或者可以返回一个默认图像\n",
    "\n",
    "        # 应用 transform，如果存在\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(np.array(image), dtype=torch.float32)\n",
    "\n",
    "        # 处理标签\n",
    "        if not self.is_test:\n",
    "            # 确保标签是 'stable_height'\n",
    "            if 'stable_height' in self.dataframe.columns:\n",
    "                label = self.dataframe.iloc[idx]['stable_height']\n",
    "                # 将 numpy.int64 转换为 torch.Tensor，指定为 float32 或 long\n",
    "                label = torch.tensor(label, dtype=torch.float32)  # 或者根据需求转换为 long\n",
    "            else:\n",
    "                raise ValueError(\"Training dataset must have a 'stable_height' column for labels.\")\n",
    "        else:\n",
    "            # 对于测试集，使用占位标签\n",
    "            label = torch.tensor(-1, dtype=torch.float32)  # 使用占位符\n",
    "\n",
    "        # 返回图像和标签\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GAN 生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, img_channels, img_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, img_channels * img_size * img_size),\n",
    "            nn.Tanh()  # 输出图像像素值在 [-1, 1] 范围\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        img = self.model(noise)\n",
    "        img = img.view(img.size(0), 3, 224, 224)\n",
    "        return img\n",
    "\n",
    "# GAN 判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, img_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_channels * img_size * img_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# GAN训练函数\n",
    "def train_gan(generator, discriminator, data_loader, config, optimizer_G, optimizer_D, criterion, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_imgs, _) in enumerate(data_loader):\n",
    "            real_imgs = real_imgs.to(config.device)\n",
    "            real_labels = torch.ones(real_imgs.size(0), 1).to(config.device)\n",
    "            fake_labels = torch.zeros(real_imgs.size(0), 1).to(config.device)\n",
    "\n",
    "            # ---------------------\n",
    "            #  训练生成器\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            noise = torch.randn(real_imgs.size(0), config.noise_dim).to(config.device)\n",
    "            gen_imgs = generator(noise)\n",
    "\n",
    "            validity = discriminator(gen_imgs)\n",
    "            g_loss = criterion(validity, real_labels)\n",
    "            g_loss.backward(retain_graph=True)  # 这里设置 retain_graph=True\n",
    "\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # ---------------------\n",
    "            #  训练判别器\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            real_pred = discriminator(real_imgs)\n",
    "            real_loss = criterion(real_pred, real_labels)\n",
    "\n",
    "            fake_pred = discriminator(gen_imgs.detach())\n",
    "            fake_loss = criterion(fake_pred, fake_labels)\n",
    "\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            d_loss.backward()  # 这里不需要 retain_graph\n",
    "\n",
    "            optimizer_D.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch}/{num_epochs}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "# 生成新图像\n",
    "\n",
    "\n",
    "# 自定义 GAN 生成的数据集\n",
    "# 修改 CustomGANImageDataset 类的 __getitem__ 方法\n",
    "\n",
    "\n",
    "\n",
    "# 训练ResNet模型\n",
    "# 训练ResNet模型\n",
    "# 训练ResNet模型\n",
    "def train(model, train_loader, config, optimizer, scheduler):\n",
    "    # 确保模型在正确的设备上\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    # 检查模型是否在正确设备上\n",
    "    print(f\"Training on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        running_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch + 1}/{config.epochs}\")\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs}\", leave=False)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(progress_bar):\n",
    "            # 确保输入和标签都移动到正确的设备上\n",
    "            inputs = inputs.to(config.device)  # 移动输入到cuda\n",
    "            labels = labels.to(config.device)  # 移动标签到cuda\n",
    "\n",
    "            optimizer.zero_grad()  # 清除梯度\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            loss = config.loss_fn(outputs.squeeze(), labels.float())\n",
    "\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # 调整学习率\n",
    "        print(f\"Epoch {epoch + 1} Train Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# 生成新图像\n",
    "# 生成新图像\n",
    "# 生成新图像\n",
    "def generate_images(generator, num_images, noise_dim, config):\n",
    "    generator = generator.to(config.device)  # 确保生成器也在设备上\n",
    "    generator.eval()\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        noise = torch.randn(num_images, noise_dim).to(config.device)  # 噪声也在设备上\n",
    "        gen_imgs = generator(noise).to(config.device)  # 生成的图像放置到设备上\n",
    "        gen_imgs = (gen_imgs + 1) / 2  # 反归一化到 [0, 1] 区间\n",
    "    return gen_imgs\n",
    "\n",
    "\n",
    "\n",
    "# 验证ResNet模型\n",
    "def evaluate(model, val_loader, config):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(config.device), labels.to(config.device)\n",
    "            outputs = model(inputs)\n",
    "            loss = config.loss_fn(outputs.squeeze(), labels.float())\n",
    "            running_loss += loss.item()\n",
    "    print(f\"Validation Loss: {running_loss / len(val_loader):.4f}\")\n",
    "\n",
    "# 初始化配置\n",
    "config = ResNetConfig()\n",
    "\n",
    "# 加载训练和验证数据集\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_dataset = CustomImageDataset(dataframe=train_df, img_dir='train', transform=transforms.ToTensor(), is_test=False)\n",
    "\n",
    "# 定义验证集（测试集）数据集和数据加载器\n",
    "val_dataset = CustomImageDataset(dataframe=test_df, img_dir='test', transform=transforms.ToTensor(), is_test=True)\n",
    "\n",
    "# DataLoader 定义\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# 构建ResNet模型\n",
    "model = ResNetModel(config).to(\"cpu\")\n",
    "generator = Generator(config.noise_dim, config.img_channels, config.img_size).to(\"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.lr)\n",
    "scheduler = StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "\n",
    "# GAN 部分\n",
    "\n",
    "discriminator = Discriminator(config.img_channels, config.img_size).to(config.device)\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=config.lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=config.lr * 0.1)  # 将判别器的学习率降低到生成器的1/10\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 训练GAN\n",
    "generator = train_gan(generator, discriminator, train_loader, config, optimizer_G, optimizer_D, criterion)\n",
    "\n",
    "# 生成新图像\n",
    "new_images = generate_images(generator, num_images=100, noise_dim=config.noise_dim, config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21db4d-3937-4c0c-a342-593c67ac8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomGANImageDataset(Dataset):\n",
    "    def __init__(self, generated_images, transform=None):\n",
    "        self.generated_images = generated_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generated_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.generated_images[idx]\n",
    "\n",
    "        # 如果 img 是 numpy 数组，则转换为 torch.Tensor\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "        # 检查 transform，如果存在且 img 是 PIL Image 或 numpy 数组，才应用 transform\n",
    "        if self.transform and not isinstance(img, torch.Tensor):\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 返回 img 和一个标签，确保标签是 torch.Tensor\n",
    "        return img, torch.tensor(0, dtype=torch.long)  # 标签为 long 类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baba9e9-409c-4705-88c6-37edcd8ad223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_device_consistency(model, inputs, labels, generated_data, config):\n",
    "    # 检查模型是否在正确的设备上\n",
    "    model_device = next(model.parameters()).device\n",
    "    print(f\"Model is on device: {model_device}\")\n",
    "\n",
    "    # 检查输入数据是否在正确的设备上\n",
    "    inputs_device = inputs.device\n",
    "    print(f\"Inputs are on device: {inputs_device}\")\n",
    "\n",
    "    # 检查标签是否在正确的设备上\n",
    "    labels_device = labels.device\n",
    "    print(f\"Labels are on device: {labels_device}\")\n",
    "\n",
    "    # 检查生成器生成的数据是否在正确的设备上\n",
    "    generated_data_device = generated_data.device\n",
    "    print(f\"Generated data is on device: {generated_data_device}\")\n",
    "\n",
    "    # 比较所有设备，确保它们一致\n",
    "    if model_device == inputs_device == labels_device == generated_data_device == config.device:\n",
    "        print(\"All tensors and model are on the correct device!\")\n",
    "    else:\n",
    "        print(\"Mismatch found in device placement! Please check the device assignment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70ad05-d5d4-4baf-9ceb-82b1db497221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设生成器生成了图像\n",
    "generated_data = generate_images(generator, num_images=32, noise_dim=config.noise_dim, config=config)\n",
    "\n",
    "# 获取一个 batch 的输入和标签\n",
    "inputs, labels = next(iter(train_loader))\n",
    "\n",
    "# 调用检查函数\n",
    "check_device_consistency(model, inputs, labels, generated_data, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d28f52-1179-4d95-a598-283d6f6a4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_dataset = CustomGANImageDataset(new_images, transform=transforms.ToTensor())\n",
    "combined_dataset = ConcatDataset([train_dataset, gan_dataset])\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=config.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf27531-c455-4d7f-aebf-a337a80c1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 遍历 combined_loader，检查数据类型\n",
    "def check_dataset_tensor_types(loader):\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        # 检查 images 的数据类型是否为 torch.Tensor\n",
    "        if not isinstance(images, torch.Tensor):\n",
    "            print(f\"Batch {batch_idx + 1}: Images are not torch.Tensor!\")\n",
    "            print(f\"Images type: {type(images)}\")\n",
    "            # 如果 images 不是 torch.Tensor，打印出它的编码\n",
    "            print(f\"Images: {images}\")\n",
    "\n",
    "        # 检查 labels 的数据类型是否为 torch.Tensor\n",
    "        if not isinstance(labels, torch.Tensor):\n",
    "            print(f\"Batch {batch_idx + 1}: Labels are not torch.Tensor!\")\n",
    "            print(f\"Labels type: {type(labels)}\")\n",
    "            # 如果 labels 不是 torch.Tensor，打印出它的编码\n",
    "            print(f\"Labels: {labels}\")\n",
    "\n",
    "        # 打印每个批次的数据类型，用于确认\n",
    "        print(f\"Batch {batch_idx + 1}: Images type: {type(images)}, Labels type: {type(labels)}\")\n",
    "        \n",
    "        # 如果检测到不是 torch.Tensor，跳出循环\n",
    "        if not isinstance(images, torch.Tensor) or not isinstance(labels, torch.Tensor):\n",
    "            break\n",
    "\n",
    "# 检查 combined_loader 中的数据类型\n",
    "check_dataset_tensor_types(combined_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4e7bf-2486-4315-8505-3a8737a6a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用生成的图像作为新数据集\n",
    "gan_dataset = CustomGANImageDataset(new_images, transform=transforms.ToTensor())\n",
    "combined_dataset = ConcatDataset([train_dataset, gan_dataset])\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# 训练ResNet模型并验证\n",
    "train(model, combined_loader, config, optimizer, scheduler)\n",
    "evaluate(model, val_loader, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56fdf4-9d86-4eb0-9849-8ff485cc573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_results(json_file):\n",
    "#     # 从 JSON 文件读取数据\n",
    "#     with open(json_file, \"r\") as f:\n",
    "#         results = json.load(f)\n",
    "\n",
    "#     # 提取训练和验证的结果\n",
    "#     train_results = results[\"train\"]\n",
    "#     val_results = results[\"validation\"]\n",
    "\n",
    "#     # 准备数据\n",
    "#     epochs = [res[\"epoch\"] for res in train_results]\n",
    "#     train_loss = [res[\"train_loss\"] for res in train_results]\n",
    "#     train_approx_acc = [res[\"train_approx_acc\"] for res in train_results]\n",
    "\n",
    "#     val_loss = val_results[\"val_loss\"]\n",
    "#     val_approx_acc = val_results[\"val_approx_acc\"]\n",
    "\n",
    "#     # 绘制 Loss 曲线\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs, train_loss, label='Train Loss', marker='o')\n",
    "#     plt.axhline(y=val_loss, color='r', linestyle='--', label='Val Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title('Loss Curve')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # 绘制近似准确率曲线\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs, train_approx_acc, label='Train Approx Acc', marker='o')\n",
    "#     plt.axhline(y=val_approx_acc, color='r', linestyle='--', label='Val Approx Acc')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Approx Accuracy')\n",
    "#     plt.title('Approx Accuracy Curve')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # 显示图像\n",
    "#     plt.tight_layout()\n",
    "# # 调用函数，绘制曲线\n",
    "# plot_results(\"resnet_result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435ea9b32a3b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 将模型加载到 CPU\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "# 切换模型到评估模式\n",
    "model.eval()\n",
    "\n",
    "# 存储预测结果的列表\n",
    "predictions = []\n",
    "\n",
    "# 禁用梯度计算以加速推理过程\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        # 将输入数据移到 CPU 上\n",
    "        inputs = inputs.to(\"cpu\")\n",
    "\n",
    "        # 获取模型预测\n",
    "        outputs = model(inputs).squeeze()\n",
    "\n",
    "        # 将预测结果移动到 CPU，并转换为列表格式\n",
    "        preds = outputs.cpu().numpy().tolist()\n",
    "\n",
    "        # 应用四舍五入规则：大于 0.5 则进位\n",
    "        rounded_preds = [int(round(p)) for p in preds]\n",
    "\n",
    "        # 存储批次的预测结果\n",
    "        predictions.extend(rounded_preds)\n",
    "\n",
    "# 将结果与原始 DataFrame 中的文件名组合\n",
    "result = pd.DataFrame({\n",
    "    \"id\": test_dataset.dataframe.iloc[:, 0],  # 第一列文件名\n",
    "    \"stable_height\": predictions              # 模型预测结果\n",
    "})\n",
    "\n",
    "# 打印结果前几行以验证\n",
    "print(result.head())\n",
    "\n",
    "# 可选：保存结果为 CSV 文件\n",
    "result.to_csv(\"predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63007d1e-3f99-439b-a64d-c861e61385dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
